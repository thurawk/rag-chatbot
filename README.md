# ğŸ§  RAG Q&A Chatbot

This repository demonstrates how to build a **Retrieval-Augmented Generation (RAG) chatbot** using **Python + Jupyter Notebooks**.  
The chatbot can answer questions grounded in your own documents instead of hallucinating answers.

Itâ€™s built with modern tools like **LangChain**, **FAISS**, and **uv** (for fast, reliable dependency management).

---

## ğŸš€ Features

- ğŸ” Document retrieval with **FAISS** (dense search) and **BM25** (sparse search)
- ğŸ¤– Q&A chatbot powered by **LLMs** (Ollama, OpenAI, Hugging Face)
- ğŸ“š Source citation alongside answers
- ğŸ“ Step-by-step Jupyter notebooks for learning
- âš¡ Simple evaluation of RAG vs. non-RAG answers
- ğŸŒStreamlit demo app

---

## ğŸ“‚ Project Structure

```bash
rag-chatbot/
â”‚â”€â”€ README.md
â”‚â”€â”€ pyproject.toml
â”‚â”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_intro_rag.ipynb
â”‚ â”œâ”€â”€ 02_build_index.ipynb
â”‚ â”œâ”€â”€ 03_chatbot_pipeline.ipynb
â”‚ â”œâ”€â”€ 04_evaluation.ipynb
â”‚ â””â”€â”€ 05_streamlit_app.ipynb
â”‚â”€â”€ data/knowledge/
â”‚â”€â”€ src/rag_chatbot/
```

---

## ğŸ› ï¸ Tech Stack

- **Languages:** Python  
- **AI/ML:** LangChain, FAISS, BM25, SentenceTransformers 
- **LLMs:** Ollama (local), OpenAI, Hugging Face
- **Tools:** Jupyter, Streamlit, GitHub
- **Package Management:** [uv](https://docs.astral.sh/uv/)

---

## âš¡ Quickstart (with uv)

### 1. Clone the repo

```bash
git clone https://github.com/<thrawk>/rag-chatbot.git
cd rag-chatbot
```

### 2. Install dependencies

```bash
uv sync
```

### 3. Launch Jupyter

```bash
uv run jupyter lab
```

### 4. Explore notebooks

```bash
notebooks/01_intro_rag.ipynb
```

### ğŸ¯ Example

```bash
Query: What is Retrieval-Augmented Generation?
Chatbot: Retrieval-Augmented Generation (RAG) is a technique that combines document retrieval with large language models. Instead of generating answers purely from memory, the model retrieves relevant knowledge chunks and uses them to generate more accurate responses.

ğŸ“– Sources: [RAG.txt, line 12â€“27]
```
